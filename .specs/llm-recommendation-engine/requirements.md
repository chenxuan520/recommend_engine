# 需求文档

## 介绍

本系统是一个基于大语言模型（LLM）的通用推荐引擎。首个版本（MVP）将专注于**音乐推荐**场景。系统利用符合 OpenAI 协议的大模型作为召回源，根据用户的收藏列表生成推荐结果。系统设计强调高扩展性，以便未来接入电影、书籍等其他类型的推荐。用户管理采用轻量级的静态配置文件方案，同时包含推荐历史去重机制。

## 需求

### 需求 1: 静态用户配置管理

**用户故事:** 作为一个系统管理员，我希望通过静态配置文件来管理用户及其收藏的音乐列表，以便在无需开发注册登录和数据库功能的情况下快速运行系统。

#### 验收标准

1. 当系统启动时，那么系统应该从指定的配置文件（如 YAML/JSON）中加载所有用户的 ID、基本信息及“收藏音乐列表”。
2. 如果配置文件不存在或格式校验失败，那么系统应该记录错误并拒绝启动。
3. 当用户请求推荐时，那么系统应该能根据用户 ID 获取其内存中的配置信息。

### 需求 2: 基于 LLM 的音乐召回

**用户故事:** 作为一个用户，我希望系统能根据我收藏的音乐，利用大语言模型的知识库推荐相似或相关的音乐，以便发现我可能喜欢的新歌。

#### 验收标准

1. 当触发推荐流程时，那么系统应该将用户的“收藏音乐列表”组装成 Prompt。
2. 当调用 LLM 接口时，那么系统应该使用符合 OpenAI 协议的 API（支持配置 Base URL 和 API Key）。
3. 如果 LLM 返回非结构化数据，那么系统应该尝试将其解析为结构化的音乐名称列表。
4. 接口设计上，音乐推荐应作为一种“推荐类型”的实现，核心召回逻辑应定义为通用接口，以支持未来扩展。

### 需求 3: 推荐历史过滤（去重）

**用户故事:** 作为一个用户，我希望系统不要推荐我在过去 7 天内已经被推荐过的音乐，以便我每次都能获得新鲜的推荐内容。

#### 验收标准

1. 当 LLM 返回推荐候选集后，那么系统应该获取该用户过去 7 天的推荐历史记录。
2. 如果候选集中的音乐名称存在于 7 天内的历史记录中，那么系统应该将该音乐从最终结果中剔除。
3. 当成功向用户展示推荐结果后，那么系统应该将这些结果追加记录到该用户的历史记录中（需持久化，如本地文件或轻量级 KV）。

### 需求 4: 高扩展性架构

**用户故事:** 作为一个开发者，我希望系统的核心流程（用户上下文获取 -> 召回 -> 过滤 -> 结果）是抽象的，以便未来不仅能推荐音乐，还能推荐其他内容。

#### 验收标准

1. 当实现代码时，那么必须定义通用的 `RecommendationContext`、`RecallSource`（召回源）和 `Filter`（过滤器）接口。
2. 音乐推荐的具体逻辑（如 Prompt 模板、音乐对象定义）应该实现上述接口，而不是硬编码在主流程中。
